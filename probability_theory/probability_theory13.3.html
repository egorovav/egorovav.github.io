<html>
<head>
<meta charset="utf-8" />
<title>Probability theory 13.3</title>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}, TeX: {extensions: ["mediawiki-texvc.js", "autobold.js"], unicode: {
	fonts: "STIXGeneral, 'Arial Unicode MS'"}}
});
</script>
<script type="text/javascript" async
src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_HTML">
<!--script type="text/javascript" async src="../../../MathJax/MathJax.js?config=TeX-AMS_HTML"--></script>
<link rel="stylesheet" href="style.css">
</head>
<body>

<a href="./probability_theory13.1.html">previous</a> <a href="./math_contents.html">contents</a> <a href="./probability_theory13.5.html">next</a>
<br>


<h5 id="13.3">13.3 Проверка некоторых сложных гипотез о параметрах $N(\mu,\sigma^2)$.</h5>

<p id="Definition13.8"><b>Определение 13.8:</b>
Статистический критерий называется состоятельным, если $\beta(\mu)\to0$ при $n\to\infty$, 
то есть вероятность ошибки второго рода стремится к нулю при росте объема выборки.
<br><br>
<p id="Example13.7"><b>Пример 13.7:</b>
Пусть $\xi\sim{N}(\mu,\sigma^2)$, где $\sigma^2$ известно, $\mu$ неизвестно. 
Построим критерий для проверки гипотезы $H_0$: $\mu\geq\mu_0$ против альтернативы $H_1$: $\mu<\mu_0$.
<br>
Рассмотрим критерий:
$$\begin{cases}\overline{x}\geq{\mu_0}-\delta\Rightarrow{H}_0 \\ \overline{x}<\mu_0-\delta\Rightarrow{H}_1\end{cases}.$$
$$
\alpha(\mu)=P(H_1/H_0)=P\left\{\overline{x}<\mu_0-\delta/H_0\right\}=P\left\{\frac{\overline{x}-\mu}{\sigma}\sqrt{n}<
\frac{\mu_0-\delta-\mu}{\sigma}\sqrt{n}/H_0\right\}=\Phi\left(\frac{\mu_0-\delta-\mu}{\sigma}\sqrt{n}\right)
$$
Так как функция $\Phi(x)$ возрастающая, то 
$$\sup_{\mu\geq\mu_0}\alpha(\mu)=\alpha(\mu_0).$$
Пусть $\alpha_0$ ошибка первого рода (уровень значимости критерия), тогда
$$\alpha_0\geq\sup_{\mu\geq\mu_0}\alpha(\mu)=\alpha(\mu_0)=\Phi\left(\frac{-\delta\sqrt{n}}{\sigma}\right).$$
Так как функция $\Phi(x)$ возрастает, то можем применить к неравенству обратную функцию $\Phi^{-1}$, тогда
$$t_{\alpha_0}\geq\frac{-\delta\sqrt{n}}{\sigma}\Rightarrow\delta\leq-\frac{\sigma{t}_{\alpha_0}}{\sqrt{n}}.$$
Таким образом, положив $\delta=-\sigma{t}_{\alpha_0}/\sqrt{n}$ получим критерий уровня значимости $\alpha_0$ с вероятностью ошибки второго рода
$$
\beta(\mu)=P(H_0/H_1)=P\{\overline{x}\geq\mu_0-\delta/H_1\}=
P\left\{\frac{\overline{x}-\mu}{\sigma}\sqrt{n}\geq\frac{\mu_0-\delta-\mu}{\sigma}\sqrt{n}/H_1\right\}=
1-\Phi\left(\frac{\mu_0-\delta-\mu}{\sigma}\sqrt{n}\right)=1-\Phi\left(\frac{\mu_0-\mu}{\sigma}\sqrt{n}+t_{\alpha_0}\right).
$$
Следовательно, полученный критерий является состоятельным, так как функция $\Phi(x)\to1$ при $x\to\infty$, следовательно, $\beta(\mu)\to0$ при $n\to\infty$.
<br>
Функция мощности критерия есть
$$W(\mu)=\begin{cases}\alpha(\mu), & \mu\geq\mu \\ 1-\beta(\mu), & \mu<\mu_0\end{cases}.$$
<br><br>
<p id="Example13.8"><b>Пример 13.8:</b>
Для проверки гипотезы $H_0$: $\mu=\mu_0$ против альтернативы $H_1$: $\mu\neq\mu_0$ можно использовать критерий 
$$\begin{cases}|\overline{x}-\mu_0|<\delta\Rightarrow{H}_0 \\ |\overline{x}-\mu_0|\geq\delta\Rightarrow{H}_1\end{cases},$$
где $\delta$ находится аналогично примеру 13.7.
<br><br>
<p id="Example13.9"><b>Пример 13.9:</b>
Для проверки гипотезы $H_0$: $\mu_0<\mu<\mu_1$ против альтернативы $H_1$: $\mu\notin(\mu_0,\mu_1)$ можно использовать критерий 
$$\begin{cases}\mu_0-\delta<\overline{x}<\mu_1+\delta & \Rightarrow{H}_0\\ \overline{x}\notin(\mu_0-\delta,\mu_1+\delta) & \Rightarrow{H}_1\end{cases},$$
где $\delta$ находится аналогично <a href="#Example13.7">примеру 13.7</a>.
<br><br>
<p id="Example13.10"><b>Пример 13.10: Критерий Стьюдента.</b><br>
Пусть $\xi\sim{N}(\mu,\sigma^2)$, где $\mu$ и $\sigma^2$ неизвестны. 
Построим критерий для проверки гипотезы $H_0$: $\mu=\mu_0$ против альтернативы $H_1$: $\mu\neq\mu_0$. Несмотря на то, 
что множество значений параметра $\mu$ состоит из одного элемента гипотеза $H_0$ является сложной, 
так как она не определяет однозначно распределение случайной величины $\xi$, в силу того, что $\sigma^2$ неизвестно.
Пусть $(X_1,\ldots,X_n)$ выборка над $\xi$, тогда при верной $H_0$
$$\frac{\overline{x}-\mu_0}{\sigma}\sqrt{n}\sim{N}(0,1),\,\frac{nS^2}{\sigma^2}\sim\chi_{n-1}^2,$$
см. например доказательство теоремы Фишера (<a href="./probability_theory12.6.html#Theorem12.9">теорема 12.9</a>). 
Тогда аналогично п. 2 примера 13.9 при верной $H_0$
$$\frac{\overline{x}-\mu}{\sigma}\sqrt{n}=\frac{\overline{x}-\mu_0}{\sigma}\sqrt{n}:\sqrt{\frac{nS^2}{\sigma^2(n-1)}}\sim{St}_{n-1}.$$
Следовательно, для проверки гипотезы $H_0$ можно использовать критерий
$$
\begin{cases}
|(\overline{x}-\mu_0)\sqrt{n-1}/S|<\delta\Rightarrow{H}_0 \\
|(\overline{x}-\mu_0)\sqrt{n-1}/S|\geq\delta\Rightarrow{H}_1,
\end{cases}
$$
где $\delta$ при фиксированном значении ошибки первого рода $\alpha$ находим из условия 
$$
\alpha=P(H_1/H_0)=P\left\{\left|\frac{\overline{x}-\mu_0}{S}\sqrt{n-1}\right|\geq\delta/H_0\right\}=
2-2P\left\{\frac{\overline{x}-\mu_0}{S}\sqrt{n-1}<\delta\right\}\Rightarrow\delta=t_{1-\alpha/2}.
$$
где $t_{1-\alpha/2}$ квантиль уровня $1-\alpha/2$ распределения Стьюдента с $n-1$ степенью свободы.
<br><br>
<p id="Example13.11"><b>Пример 13.11:</b>
Пусть $\xi\sim{N}(\mu,\sigma^2)$ где $\mu$ известно, а $\sigma^2$ нет. 
Построим критерий для проверки гипотезы $H_0$: $\sigma^2\leq\sigma_0^2$ против альтернативы $H_1$: $\sigma^2>\sigma_0^2$. Обозначим выборочную дисперсию
$$S_0^2:=\frac1{n}\sum_{i=1}^n(x_i-\mu)^2.$$
Рассмотрим критерий 
$$\begin{cases}S_0^2/\sigma_0^2\leq1+\delta\Rightarrow{H_0} \\ S_0^2/\sigma_0^2>1+\delta\Rightarrow{H}_1 \end{cases},$$
где при фиксированной ошибке первого рода $\alpha$ находим $\delta$ из условия
$$
\alpha(\sigma^2)=P(H_1/H_0)=P\left\{\frac{S_0^2}{\sigma_0^2}>1+\delta/H_0\right\}=P\left\{\frac{nS_0^2}{\sigma^2}>
\frac{n(1+\delta)\sigma_0^2}{\sigma^2}\right\}=1-P\left\{\frac{nS_0^2}{\sigma^2}>\frac{n(1+\delta)\sigma^2}{\sigma_0^2}\right\}.
$$
Так как для любого $i\in\overline{1,n}$ $(X_i-\mu)/\sigma\sim{N}(0,1)$, то 
$$\frac{nS_0^2}{\sigma^2}=\sum_{i=1}^n\left(\frac{x_i-\mu}{\sigma}\right)^2\sim\chi_n^2.$$
Следовательно, обозначив функцию распределения $\chi_n^2$ как $F_n(x)$ получим 
$$\alpha=1-F_n\left(\frac{n(1+\delta)\sigma_0^2}{\sigma^2}\right).$$
При верной гипотезе $H_0$: $\sigma^2\leq\sigma_0^2$, следовательно, в силу возрастания функции распределения 
$$\alpha(\sigma^2)\leq\alpha(\sigma_0^2)=1-F_n(n(1+\delta)).$$ 
Тогда обозначив квантиль уровня $1-\alpha$ для распределения $\chi_n^2$ как $t_{1-\alpha}$ и 
положив $\delta=t_{1-\alpha}/n-1$ получим критерий уровня значимости $\alpha$ с вероятностью ошибки второго рода
$$
\beta(\sigma^2)=P(H_0/H_1)=P\left\{\frac{S_0^2}{\sigma_0^2}<1+\delta/H_1\right\}=
P\left\{\frac{nS_0^2}{\sigma^2}<\frac{n(1+\delta)\sigma_0^2}{\sigma^2}/H_1\right\}=F_n\left(\frac{n(1+\delta)\sigma_0^2}{\sigma^2}\right)
$$
Если $\mu$ не известно, то вместо статистики $S_0$ используют статистику 
$$S^2:=\frac1{n}\sum_{i=1}^n(X_i-\overline{X})^2$$
при этом для определения $\delta$ используют теорему Фишера (<a href="./probability_theory12.6.html#Theorem12.9">теорема 12.9</a>) из которой следует, что
$$\frac{nS^2}{\sigma^2}\sim\chi_{n-1}^2.$$
Критерий будет такой же при $\delta=t_{1-\alpha}/n-1$, где $t_{1-\alpha}$ квантиль уровня $1-\alpha$ для распределения $\chi_{n-1}^2$.
<br><br>
<p id="Example13.12"><b>Пример 13.12: Проверка гипотезы о равенстве математических ожиданий двух нормальных совокупностей.</b><br>
<ol>
<li>
Пусть $(X_1,\ldots,X_{n_1})$ выборка над $\xi\sim{N}(\mu_1,\sigma^2)$, $(Y_1,\ldots,Y_{n_2})$ выборка над $\eta\sim{N}(\mu_2,\sigma^2)$, 
где $\sigma^2$ известно, а $\mu_1$ и $\mu_2$ - нет. 
Построим критерий проверки гипотезы $H_0$: $\mu_1=\mu_2$ против альтернативы $H_1$: $\mu_1\neq\mu_2$. 
Будем считать, что выборки независимы, тогда по теоремам <a href="./probability_theory7.3.html#Theorem7.12">7.12</a> и 
<a href="./probability_theory4.3.html#Theorem4.11">4.11</a>
$$\overline{x}-\overline{y}\sim{N}\left(\mu_1-\mu_2,\frac{\sigma^2}{n_1}+\frac{\sigma^2}{n_2}\right).$$
Обозначим
$$T(x_1,\ldots,x_{n_1},y_1,\ldots,y_{n_2}):=\frac{\overline{x}-\overline{y}}{\sigma}\sqrt{\frac{n_1n_2}{n_1+n_2}}.$$
Тогда при верной гипотезе $H_0$: $T\sim{N}(0,1)$ и для её проверки можно использовать критерий из примера 12.8 при $\mu_0=0$
$$\begin{cases}|T|<\delta\Rightarrow{H}_0 \\ |T|\geq\delta\Rightarrow{H}_1\end{cases},$$
где при заданной ошибке первого рода $\alpha$ значение $\delta$ находится из условия
$$\alpha=P(H_1/H_0)=P\left\{|T|\geq\delta\right\}=1-\Phi(\delta)-\Phi(-\delta)=2\Phi(-\delta)\Rightarrow\delta=-t_{\alpha/2}$$
</li><li>
Пусть теперь $\sigma^2$ так же неизвестно. Обозначим
$$S_x^2:=\frac1{n_1}\sum_{i=1}^{n_1}(x_i-\overline{x})^2;\,S_y^2:=\frac1{n_2}\sum_{i=1}^{n_2}(y_i-\overline{y})^2.$$
Тогда по теореме Фишера (<a href="./probability_theory12.6.html#Theorem12.9">теорема 12.9</a>)
$$\frac{n_1S_x^2}{\sigma^2}\sim\chi_{n_1-1}^2;\,\frac{n_2S_y^2}{\sigma^2}\sim\chi_{n_2-1}^2.$$
Так как $S_x^2$ и $S_y^2$ независимы, то
$$\frac{n_1S_x^2}{\sigma^2}+\frac{n_2S_y^2}{\sigma^2}\sim\chi_{n_1+n_2-2}^2.$$
Обозначим 
$$
T(x_1,\ldots,x_{n_1},y_1,\ldots,y_{n_2}):=\frac{\overline{x}-\overline{y}}{\sigma}\sqrt\frac{n_1n_2}{n_1+n_2}:\sqrt{\frac{n_1S_x^2+n_2S_y^2}{\sigma^2(n_1+n_2-2)}}=
\frac{\overline{x}-\overline{y}}{\sqrt{n_1S_x^2+n_2S_y^2}}\sqrt{\frac{n_1n_2(n_1+n_2-2)}{n_1+n_2}}
$$
Так как при верной $H_0$ (см. п. 1)
$$\frac{\overline{x}-\overline{y}}{\sigma}\sqrt{\frac{n_1n_2}{n_1+n_2}}\sim{N}(0,1),$$
то аналогично <a href="#Example13.9">примеру 13.9</a> $T\sim{S}t_{n_1+n_2-2}$. Далее критерий строится аналогично пункту 1.
</li>
</ol>

<h5 id="13.4">13.4 Проверка гипотез о независимости признаков.</h5>

<p id="Example13.13"><b>Пример 13.13:</b>
Пусть $\{A_1,\ldots,A_r\}$ множество значений случайной величины $\xi$, $\{B_1,\ldots,B_s\}$ 
множество значений случайной величины $\eta$. Пусть $((X_1,Y_1),\ldots, (X_n,Y_n))$ - совместная выборка над $\xi$ и $\eta$, 
где для любого $i\in\overline{1,n}$ $X_i\sim\xi$, $Y_i\sim\eta$. Для любого $i\in\overline{1,r}$, 
$j\in\overline{1,s}$ обозначим $p_{i,j}$ вероятность того, что элемент выборки принимает значение $(A_i,B_j)$, тогда
$$p_{i\cdot}:=P(\xi=A_i)=\sum_{j=1}^sp_{i,j};\,p_{\cdot{j}}:=P(\eta=B_j)=\sum_{i=1}^rp_{i,j}.$$
Построим критерий для проверки гипотезы $H_0$: $p_{i,j}=p_{i\cdot}p_{\cdot{j}}$ для любого $i\in\overline{1,r}$, $j\in\overline{1,s}$.

Обозначим $\nu_{i,j}$ как число элементов выборки равных $(A_i,B_j)$, тогда $\sum_{i,j}\nu_{i,j}=n$. 
Значения $p_{1\cdot},\ldots,p_{r\cdot}$, $p_{\cdot{1}},\ldots,p_{\cdot{s}}$ неизвестны, но так как 
$$\sum_{i=1}^rp_{i\cdot}=\sum_{j=1}^sp_{\cdot{j}}=1,$$ 
то число оцениваемых параметров равно $m=r+s-2$. 
Пременив для оценки параметров метод $\chi^2$ (<a href="./probability_theory12.6.html#Note12.3">замечание 12.3</a>) получим 
$$
\begin{cases}
\sum_{i=1}^r\sum_{j=1}^s\frac{\nu_{i,j}}{p_{i\cdot}p_{\cdot{j}}}\frac{\partial(p_{i\cdot}p_{\cdot{j}})}{\partial{p}_l}=0;\,l\in\overline{1,r-1} \\
\sum_{i=1}^r\sum_{j=1}^s\frac{\nu_{i,j}}{p_{i\cdot}p_{\cdot{j}}}\frac{\partial(p_{i\cdot}p_{\cdot{j}})}{\partial{p}_k}=0;\,k\in\overline{1,s-1}.
\end{cases}
$$
Так как при $r\neq{l}$
$$\frac{\partial{p}_{r\cdot}}{\partial{p_{l\cdot}}}=\frac{\partial(1-p_{1\cdot}-\cdots-p_{r-1\cdot})}{\partial{p}_{l\cdot}}=-1,$$ то 
$$\frac{\partial{p}_{i\cdot}}{\partial{p}_{l\cdot}}=\begin{cases}1, & i = l \\ 0, & i\neq{l},i\neq{r} \\ -1, & i = r\end{cases},$$
аналогично
$$\frac{\partial{p}_{\cdot{j}}}{\partial{p}_{\cdot{k}}}=\begin{cases}1, & j = k \\ 0, & j\neq{k},j\neq{r} \\ -1, & j = r\end{cases},$$
следовательно,
$$
\begin{cases}
\sum_{i=1}^r\left(\frac{\nu_{i,k}}{p_{\cdot{k}}}-\frac{\nu_{i,s}}{p_{\cdot{s}}}\right)=0;\,l\in\overline{1,r-1} \\
\sum_{j=1}^s\left(\frac{\nu_{l,j}}{p_{l\cdot}}-\frac{\nu_{r,j}}{p_{r\cdot}}\right)=0;\,k\in\overline{1,s-1}.
\end{cases}
$$
Обозначим $\nu_{l\cdot}:=\sum_{j=1}^s\nu_{l,j}$, $\nu_{\cdot{k}}:=\sum_{i=1}^r\nu_{i,k}$, тогда
$$
\begin{cases}
\frac{\nu_{l\cdot}}{p_{l\cdot}}-\frac{\nu_{r\cdot}}{p_{r\cdot}}=0;\,l\in\overline{1,r-1} \\
\frac{\nu_{\cdot{k}}}{p_{\cdot{k}}}-\frac{\nu_{\cdot{s}}}{p_{\cdot{s}}}=0;\,k\in\overline{1,s-1}
\end{cases}
$$
 Обозначим $c_1:=\nu_{r\cdot}/p_{r\cdot}$, $c_2:=\nu_{\cdot{s}}/p_{\cdot{s}}$, тогда
$$
 \begin{cases}
 \nu_{l\cdot}/p_{l\cdot}=c_1;\, l\in\overline{1,r} \\
 \nu_{\cdot{k}}/p_{\cdot{k}}=c_2;\, k\in\overline{1,s}
 \end{cases}\Rightarrow
  \begin{cases}
 \nu_{l\cdot}=c_1p_{l\cdot};\, l\in\overline{1,r} \\
 \nu_{\cdot{k}}=c_2p_{\cdot{k}};\, k\in\overline{1,s}
 \end{cases}\Rightarrow
 \begin{cases}
 c_1\sum_{l=1}^rp_{l\cdot}=\sum_{l=1}^r\nu_{l\cdot}=n \\ 
 c_2\sum_{k=1}^sp_{\cdot{k}}=\sum_{k=1}^s\nu_{\cdot{k}}=n
 \end{cases}\Rightarrow
 \begin{cases}c_1=n \\ c_2 = n\end{cases}\Rightarrow
 \begin{cases}
 p_{l\cdot}=\frac{\nu_{l\cdot}}{n};\, l\in\overline{1,r} \\
 p_{\cdot{k}}=\frac{\nu_{\cdot{k}}}{n};\, k\in\overline{1,s}
 \end{cases}
$$
 Тогда по теореме Пирсона (<a href="./probability_theory12.6.html#Theorem12.7">теорема 12.7</a>) при верной гипотезе $H_0$
$$
\chi^2=\sum_{i,j}\frac{(\nu_{i,j}-p_{i\cdot}p_{\cdot{j}})^2}{np_{i\cdot}p_{\cdot{j}}}=
\sum_{i,j}\frac{(\nu_{i,j}-\nu_{i\cdot}\nu_{\cdot{j}}/n)^2}{\nu_{i\cdot}\nu_{\cdot{j}}/n}\sim\chi_{(r-1)(s-1)-1}^2.
$$
Следовательно, искомый критерий может быть сформулирован в следующем виде 
$$\begin{cases}\chi^2&ltc\Rightarrow{H_0} \\ \chi^2\geq{c}\Rightarrow{H}_1\end{cases},$$
где значение $c$ при известной ошибке первого рода $\alpha$ находится из соотношения
$$\alpha=P(H_1/H_0)=p\{F(\overline{x},\overline{y})\geq{c}/H_0\},$$
обратное значение для функции $F$ находится по таблицам распределения $\chi_{(r-1)(s-1)-1}^2$.
<br><br>

<br><br>
<a href="./probability_theory13.1.html">previous</a> <a href="./math_contents.html">contents</a> <a href="./probability_theory13.5.html">next</a>